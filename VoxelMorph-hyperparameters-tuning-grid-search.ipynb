{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ea22b4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SwinTransformerSys expand initial----depths:[2, 2, 2, 2];depths_decoder:[1, 2, 2, 2];drop_path_rate:0.0;num_classes:2\n",
      "---final upsample expand_first---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/monika/miniconda3/envs/miccaienv/lib/python3.9/site-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2157.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.56 mins] After 2 epochs with n 3 lamda 0.4 4 batch_size,  num_workers 2 alpha 0.001 beta 0.7 Average training loss is  tensor(5.4967) and average DICE score is tensor(0.6134) and average cc loss is tensor(0.5208, grad_fn=<DivBackward0>)\n",
      "[ 0.12 mins] After 2 epochs, the Average validations loss is  tensor(0.5604) and average DICE score is tensor(0.6007)\n",
      "best hparams: ('max_epochs', 1, 'n', 3, 'lamda', 0.4, 4, 'batch_size, ', 'num_workers', 2, 'alpha', 0.001, 'beta', 0.7)\n",
      "[ 0.58 mins] After 3 epochs with n 3 lamda 0.4 4 batch_size,  num_workers 2 alpha 0.001 beta 0.7 Average training loss is  tensor(5.4940) and average DICE score is tensor(0.6125) and average cc loss is tensor(0.5203, grad_fn=<DivBackward0>)\n",
      "[ 0.13 mins] After 3 epochs, the Average validations loss is  tensor(0.5592) and average DICE score is tensor(0.6020)\n",
      "best hparams: ('max_epochs', 2, 'n', 3, 'lamda', 0.4, 4, 'batch_size, ', 'num_workers', 2, 'alpha', 0.001, 'beta', 0.7)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    212\u001b[0m                                 \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m[\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{0:.2f}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat((time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m60\u001b[39m), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmins]\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAfter\u001b[39m\u001b[38;5;124m'\u001b[39m, epoch \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepochs, the Average validations loss is \u001b[39m\u001b[38;5;124m'\u001b[39m, val_loss \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m    213\u001b[0m                                       params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbatch_size\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(validation_set), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mand average DICE score is\u001b[39m\u001b[38;5;124m'\u001b[39m, val_dice_score\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m*\u001b[39m params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbatch_size\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(validation_set))\n\u001b[1;32m    214\u001b[0m                                 \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbest hparams: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_hparams\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 220\u001b[0m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    183\u001b[0m cc_sm_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    184\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_fixed, batch_moving \u001b[38;5;129;01min\u001b[39;00m training_generator:\n\u001b[0;32m--> 185\u001b[0m     loss, dice, updated_lr, cc_sm \u001b[38;5;241m=\u001b[39m \u001b[43mvm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_moving\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_fixed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mupdated_lr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    186\u001b[0m     train_dice_score \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m dice\u001b[38;5;241m.\u001b[39mdata\n\u001b[1;32m    187\u001b[0m     train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mdata\n",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36mVoxelMorph.train_model\u001b[0;34m(self, batch_moving, batch_fixed, lr, n, lamda, return_metric_score)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     75\u001b[0m batch_fixed, batch_moving \u001b[38;5;241m=\u001b[39m batch_fixed\u001b[38;5;241m.\u001b[39mto(\n\u001b[1;32m     76\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice), batch_moving\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m---> 77\u001b[0m registered_image \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvoxelmorph\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_moving\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_fixed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     78\u001b[0m train_loss, cc_sm_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcalculate_loss(\n\u001b[1;32m     79\u001b[0m     registered_image, batch_fixed, n, lamda)\n\u001b[1;32m     80\u001b[0m train_loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/miniconda3/envs/miccaienv/lib/python3.9/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1103\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Dokumenty/MICCAI/voxelmorph2d.py:963\u001b[0m, in \u001b[0;36mVoxelMorph2d.forward\u001b[0;34m(self, moving_image, fixed_image)\u001b[0m\n\u001b[1;32m    961\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, moving_image, fixed_image):\n\u001b[1;32m    962\u001b[0m     x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([moving_image, fixed_image], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m--> 963\u001b[0m     deformation_matrix \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mswin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    964\u001b[0m     registered_image \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspatial_transform(moving_image, deformation_matrix)\n\u001b[1;32m    965\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m registered_image\n",
      "File \u001b[0;32m~/miniconda3/envs/miccaienv/lib/python3.9/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1103\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Dokumenty/MICCAI/voxelmorph2d.py:831\u001b[0m, in \u001b[0;36mSwinTransformerSys.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    829\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m    830\u001b[0m     x, x_downsample \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward_features(x)\n\u001b[0;32m--> 831\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward_up_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_downsample\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    832\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mup_x4(x)\n\u001b[1;32m    834\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/Dokumenty/MICCAI/voxelmorph2d.py:809\u001b[0m, in \u001b[0;36mSwinTransformerSys.forward_up_features\u001b[0;34m(self, x, x_downsample)\u001b[0m\n\u001b[1;32m    807\u001b[0m         x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([x, x_downsample[\u001b[38;5;241m3\u001b[39m \u001b[38;5;241m-\u001b[39m inx]], \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    808\u001b[0m         x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconcat_back_dim[inx](x)\n\u001b[0;32m--> 809\u001b[0m         x \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_up\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    811\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm_up(x)  \u001b[38;5;66;03m# B L C\u001b[39;00m\n\u001b[1;32m    813\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/miniconda3/envs/miccaienv/lib/python3.9/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1103\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Dokumenty/MICCAI/voxelmorph2d.py:589\u001b[0m, in \u001b[0;36mBasicLayer_up.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    587\u001b[0m         x \u001b[38;5;241m=\u001b[39m checkpoint\u001b[38;5;241m.\u001b[39mcheckpoint(blk, x)\n\u001b[1;32m    588\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 589\u001b[0m         x \u001b[38;5;241m=\u001b[39m \u001b[43mblk\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    590\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupsample \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    591\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupsample(x)\n",
      "File \u001b[0;32m~/miniconda3/envs/miccaienv/lib/python3.9/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1103\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Dokumenty/MICCAI/voxelmorph2d.py:321\u001b[0m, in \u001b[0;36mSwinTransformerBlock.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    318\u001b[0m x_windows \u001b[38;5;241m=\u001b[39m x_windows\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwindow_size \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwindow_size, C)  \u001b[38;5;66;03m# nW*B, window_size*window_size, C\u001b[39;00m\n\u001b[1;32m    320\u001b[0m \u001b[38;5;66;03m# W-MSA/SW-MSA\u001b[39;00m\n\u001b[0;32m--> 321\u001b[0m attn_windows \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_windows\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattn_mask\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# nW*B, window_size*window_size, C\u001b[39;00m\n\u001b[1;32m    323\u001b[0m \u001b[38;5;66;03m# merge windows\u001b[39;00m\n\u001b[1;32m    324\u001b[0m attn_windows \u001b[38;5;241m=\u001b[39m attn_windows\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwindow_size, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwindow_size, C)\n",
      "File \u001b[0;32m~/miniconda3/envs/miccaienv/lib/python3.9/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1103\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Dokumenty/MICCAI/voxelmorph2d.py:208\u001b[0m, in \u001b[0;36mWindowAttention.forward\u001b[0;34m(self, x, mask)\u001b[0m\n\u001b[1;32m    204\u001b[0m     attn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msoftmax(attn)\n\u001b[1;32m    206\u001b[0m attn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattn_drop(attn)\n\u001b[0;32m--> 208\u001b[0m x \u001b[38;5;241m=\u001b[39m (\u001b[43mattn\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m@\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m)\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39mreshape(B_, N, C)\n\u001b[1;32m    209\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproj(x)\n\u001b[1;32m    210\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproj_drop(x)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import voxelmorph2d as vm2d\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils import data\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage.io as io\n",
    "import os\n",
    "from skimage.transform import resize\n",
    "import multiprocessing as mp\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib.lines import Line2D\n",
    "use_gpu = torch.cuda.is_available()\n",
    "import sys\n",
    "\n",
    "\n",
    "class VoxelMorph():\n",
    "    \"\"\"\n",
    "    VoxelMorph Class is a higher level interface for both 2D and 3D\n",
    "    Voxelmorph classes. It makes training easier and is scalable.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, input_dims, use_gpu=False):\n",
    "        updated_lr = 0.001\n",
    "        self.dims = input_dims\n",
    "        self.vm = vm2d\n",
    "        self.voxelmorph = vm2d.VoxelMorph2d(input_dims[0] * 2, use_gpu)\n",
    "        self.optimizer = optim.Adam(self.voxelmorph.parameters(), lr=updated_lr, weight_decay=0, amsgrad=True)\n",
    "        self.criterion = nn.MSELoss()\n",
    "        #self.optimizer = optim.SGD(\n",
    "        #    self.voxelmorph.parameters(), lr=1e-4, momentum=0.99)\n",
    "        \n",
    "        self.params = {'batch_size': 3,\n",
    "                       'shuffle': True,\n",
    "                       'num_workers': 6,\n",
    "                       'worker_init_fn': np.random.seed(42)\n",
    "                       }\n",
    "        \n",
    "        \n",
    "        self.device = torch.device(\"cuda:0\" if use_gpu else \"cpu\")\n",
    "\n",
    "    def check_dims(self, x):\n",
    "        try:\n",
    "            if x.shape[1:] == self.dims:\n",
    "                return\n",
    "            else:\n",
    "                raise TypeError\n",
    "        except TypeError as e:\n",
    "            print(\"Invalid Dimension Error. The supposed dimension is \",\n",
    "                  self.dims, \"But the dimension of the input is \", x.shape[1:])\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.check_dims(x)\n",
    "        return voxelmorph(x)\n",
    "\n",
    "#     def calculate_loss(self, y, ytrue, n=7, lamda=10, is_training=True):\n",
    "#         loss = self.criterion(y,ytrue) + self.vm.vox_morph_loss(y, ytrue, n, lamda)\n",
    "#         #loss = self.vm.vox_morph_loss(y, ytrue, n, lamda)\n",
    "#         return loss, self.vm.vox_morph_loss(y, ytrue, n, lamda)\n",
    "    \n",
    "    def calculate_loss(self, y, ytrue, alpha, beta, n=9, lamda=0.01, is_training=True):\n",
    "        loss = alpha * self.criterion(y,ytrue) + beta * self.vm.vox_morph_loss(y, ytrue, n, lamda)\n",
    "        return loss, self.vm.vox_morph_loss(y, ytrue, n, lamda)\n",
    "\n",
    "    def train_model(self, batch_moving, batch_fixed, lr = 0.001, n=7, lamda=10, return_metric_score=True):\n",
    "        updated_lr = round(lr * np.power(1 - (0) / 5,0.9),8)\n",
    "        self.optimizer.zero_grad()\n",
    "        batch_fixed, batch_moving = batch_fixed.to(\n",
    "            self.device), batch_moving.to(self.device)\n",
    "        registered_image = self.voxelmorph(batch_moving, batch_fixed)\n",
    "        train_loss, cc_sm_loss = self.calculate_loss(\n",
    "            registered_image, batch_fixed, n, lamda)\n",
    "        train_loss.backward()\n",
    "        self.optimizer.step()\n",
    "        if return_metric_score:\n",
    "            train_dice_score = self.vm.dice_score(\n",
    "                registered_image, batch_fixed)\n",
    "            return train_loss, train_dice_score, updated_lr, cc_sm_loss\n",
    "        return train_loss, updated_lr\n",
    "\n",
    "    def get_test_loss(self, batch_moving, batch_fixed, n=7, lamda=10):\n",
    "        with torch.set_grad_enabled(False):\n",
    "            registered_image = self.voxelmorph(batch_moving, batch_fixed)\n",
    "            val_loss = self.vm.vox_morph_loss(\n",
    "                registered_image, batch_fixed, n, lamda)\n",
    "            val_dice_score = self.vm.dice_score(registered_image, batch_fixed)\n",
    "            return val_loss, val_dice_score\n",
    "\n",
    "\n",
    "class Dataset(data.Dataset):\n",
    "    \"\"\"\n",
    "    Dataset class for converting the data into batches.\n",
    "    The data.Dataset class is a pyTorch class which help\n",
    "    in speeding up  this process with effective parallelization\n",
    "    \"\"\"\n",
    "    'Characterizes a dataset for PyTorch'\n",
    "\n",
    "    def __init__(self, list_IDs):\n",
    "        'Initialization'\n",
    "        self.list_IDs = list_IDs\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the total number of samples'\n",
    "        return len(self.list_IDs)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generates one sample of data'\n",
    "        # Select sample\n",
    "        ID = self.list_IDs[index]\n",
    "\n",
    "        # Load data and get label\n",
    "        fixed_image = torch.Tensor(\n",
    "            resize(io.imread('NIH/test_xrays/' + 'a_' + ID), (224, 224, 3)))\n",
    "        moving_image = torch.Tensor(\n",
    "            resize(io.imread('NIH/test_xrays/' + 'b_' + ID), (224, 224, 3)))\n",
    "        return fixed_image, moving_image\n",
    "\n",
    "    \n",
    "ns = [3, 7, 10, 12]\n",
    "lamdas = [0.4, 3, 5, 10]\n",
    "batch_sizes = [4, 6, 15, 20, 25]\n",
    "num_workerss = [2, 4, 6]\n",
    "max_epochs = [30, 50, 70]\n",
    "alphas = [0.001, 0.01, 1]\n",
    "betas = [0.7, 0.9, 0.95]\n",
    "\n",
    "\n",
    "def main():\n",
    "    vm = VoxelMorph(\n",
    "        (3, 224, 224))  # Object of the higher level class\n",
    "    DATA_PATH = 'NIH/xrays/'\n",
    "    params = {'batch_size': 3,\n",
    "              'shuffle': True,\n",
    "              'num_workers': 6,\n",
    "              'worker_init_fn': np.random.seed(42)\n",
    "              }\n",
    "\n",
    "    # max_epochs = 5\n",
    "    filename = list(set([x.split('_')[1] + '_' + x.split('_')[2]\n",
    "                         for x in os.listdir('NIH/test_xrays/')]))\n",
    "    partition = {}\n",
    "    partition['train'], partition['validation'] = train_test_split(\n",
    "        filename, test_size=0.33, random_state=42)\n",
    "    \n",
    "    # Generators\n",
    "    training_set = Dataset(partition['train'])\n",
    "    training_generator = data.DataLoader(training_set, **params)\n",
    "\n",
    "    validation_set = Dataset(partition['validation'])\n",
    "    validation_generator = data.DataLoader(validation_set, **params)\n",
    "    \n",
    "    updated_lr = 0.001\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    best_hparams = None\n",
    "    best_loss = sys.maxsize\n",
    "    # Loop over epochs\n",
    "\n",
    "    \n",
    "    for n in ns:\n",
    "        for lamda in lamdas:\n",
    "            for batch_size in batch_sizes:\n",
    "                for num_workers in num_workerss:\n",
    "                    for alpha in alphas:\n",
    "                        for beta in betas:\n",
    "                            for epoch in max_epochs:\n",
    "                                start_time = time.time()\n",
    "                                train_loss = 0\n",
    "                                train_dice_score = 0\n",
    "                                val_loss = 0\n",
    "                                val_dice_score = 0\n",
    "                                cc_sm_loss = 0\n",
    "                                for batch_fixed, batch_moving in training_generator:\n",
    "                                    loss, dice, updated_lr, cc_sm = vm.train_model(batch_moving, batch_fixed, updated_lr)\n",
    "                                    train_dice_score += dice.data\n",
    "                                    train_loss += loss.data\n",
    "                                    cc_sm_loss += cc_sm\n",
    "                                print('[', \"{0:.2f}\".format((time.time() - start_time) / 60), 'mins]', 'After', epoch + 1, \n",
    "                                      'epochs with', 'n', n, 'lamda', lamda, batch_size, 'batch_size, ', 'num_workers', \n",
    "                                      num_workers, 'alpha', alpha, 'beta', beta, 'Average training loss is ', train_loss *\n",
    "                                      params['batch_size'] / len(training_set), 'and average DICE score is', \n",
    "                                      train_dice_score.data * params['batch_size'] / len(training_set), \n",
    "                                      'and average cc loss is', cc_sm_loss * params['batch_size'] / len(training_set))\n",
    "                                # Testing time\n",
    "                                start_time = time.time()\n",
    "                                for batch_fixed, batch_moving in validation_generator:\n",
    "                                    # Transfer to GPU\n",
    "                                    loss, dice = vm.get_test_loss(batch_moving, batch_fixed)\n",
    "                                    val_dice_score += dice.data\n",
    "                                    val_loss += loss.data\n",
    "\n",
    "\n",
    "                                if best_hparams is None or val_loss < best_loss:\n",
    "                                    #best_hparams = (n, lamda, batch_size, num_workers, max_epochs, alpha, beta)\n",
    "                                    best_hparams = ('max_epochs', epoch, 'n', n, 'lamda', lamda, batch_size, 'batch_size, ', \n",
    "                                    'num_workers', num_workers, 'alpha', alpha, 'beta', beta)\n",
    "                                    best_loss = val_loss    \n",
    "\n",
    "\n",
    "\n",
    "                                print('[', \"{0:.2f}\".format((time.time() - start_time) / 60), 'mins]', 'After', epoch + 1, 'epochs, the Average validations loss is ', val_loss *\n",
    "                                      params['batch_size'] / len(validation_set), 'and average DICE score is', val_dice_score.data * params['batch_size'] / len(validation_set))\n",
    "                                print(f\"best hparams: {best_hparams}\")\n",
    "                     \n",
    "                        \n",
    "                        \n",
    "                        \n",
    "                                             \n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df104e9b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "miccaienv",
   "language": "python",
   "name": "miccaienv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
