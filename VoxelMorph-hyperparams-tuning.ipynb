{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d4fbb9e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SwinTransformerSys expand initial----depths:[2, 2, 2, 2];depths_decoder:[1, 2, 2, 2];drop_path_rate:0.0;num_classes:2\n",
      "---final upsample expand_first---\n",
      "[ 0.45 mins] After 2 epochs with 3 n 0.4 lamda 3 batch_size [2, 4, 6] num_workers Average training loss is  tensor(5.4424) and average DICE score is tensor(0.6067) and average cc loss is tensor(0.5166, grad_fn=<DivBackward0>)\n",
      "[ 0.11 mins] After 2 epochs, the Average validations loss is  tensor(0.5813) and average DICE score is tensor(0.6145)\n",
      "best hparams: (3, 0.4, 3, 2, [1, 2, 3])\n",
      "[ 0.64 mins] After 3 epochs with 3 n 0.4 lamda 3 batch_size [2, 4, 6] num_workers Average training loss is  tensor(5.4978) and average DICE score is tensor(0.6058) and average cc loss is tensor(0.5214, grad_fn=<DivBackward0>)\n",
      "[ 0.13 mins] After 3 epochs, the Average validations loss is  tensor(0.6235) and average DICE score is tensor(0.6130)\n",
      "best hparams: (3, 0.4, 3, 2, [1, 2, 3])\n",
      "[ 0.64 mins] After 4 epochs with 3 n 0.4 lamda 3 batch_size [2, 4, 6] num_workers Average training loss is  tensor(5.4956) and average DICE score is tensor(0.6053) and average cc loss is tensor(0.5209, grad_fn=<DivBackward0>)\n",
      "[ 0.14 mins] After 4 epochs, the Average validations loss is  tensor(0.6266) and average DICE score is tensor(0.6124)\n",
      "best hparams: (3, 0.4, 3, 2, [1, 2, 3])\n",
      "[ 0.62 mins] After 2 epochs with 3 n 0.4 lamda 3 batch_size [2, 4, 6] num_workers Average training loss is  tensor(5.4965) and average DICE score is tensor(0.6051) and average cc loss is tensor(0.5208, grad_fn=<DivBackward0>)\n",
      "[ 0.13 mins] After 2 epochs, the Average validations loss is  tensor(0.6178) and average DICE score is tensor(0.6125)\n",
      "best hparams: (3, 0.4, 3, 2, [1, 2, 3])\n",
      "[ 0.70 mins] After 3 epochs with 3 n 0.4 lamda 3 batch_size [2, 4, 6] num_workers Average training loss is  tensor(5.4751) and average DICE score is tensor(0.6059) and average cc loss is tensor(0.5191, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    258\u001b[0m     fit\u001b[38;5;241m.\u001b[39mcv_results_[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean_test_score\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    259\u001b[0m     \u001b[38;5;28mlen\u001b[39m(fit\u001b[38;5;241m.\u001b[39mcv_results_[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean_test_score\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m--> 267\u001b[0m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    229\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m    230\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_fixed, batch_moving \u001b[38;5;129;01min\u001b[39;00m validation_generator:\n\u001b[1;32m    231\u001b[0m     \u001b[38;5;66;03m# Transfer to GPU\u001b[39;00m\n\u001b[0;32m--> 232\u001b[0m     loss, dice \u001b[38;5;241m=\u001b[39m \u001b[43mvm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_test_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_moving\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_fixed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    233\u001b[0m     val_dice_score \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m dice\u001b[38;5;241m.\u001b[39mdata\n\u001b[1;32m    234\u001b[0m     val_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mdata\n",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36mVoxelMorph.get_test_loss\u001b[0;34m(self, batch_moving, batch_fixed, n, lamda)\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    111\u001b[0m     registered_image \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvoxelmorph(batch_moving, batch_fixed)\n\u001b[0;32m--> 112\u001b[0m     val_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvox_morph_loss\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    113\u001b[0m \u001b[43m        \u001b[49m\u001b[43mregistered_image\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_fixed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlamda\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    114\u001b[0m     val_dice_score \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvm\u001b[38;5;241m.\u001b[39mdice_score(registered_image, batch_fixed)\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m val_loss, val_dice_score\n",
      "File \u001b[0;32m~/Dokumenty/MICCAI/voxelmorph2d.py:1048\u001b[0m, in \u001b[0;36mvox_morph_loss\u001b[0;34m(y, ytrue, n, lamda)\u001b[0m\n\u001b[1;32m   1046\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvox_morph_loss\u001b[39m(y, ytrue, n\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m7\u001b[39m, lamda\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m):\n\u001b[1;32m   1047\u001b[0m     \u001b[38;5;66;03m#cc = cross_correlation_loss(y, ytrue, n)\u001b[39;00m\n\u001b[0;32m-> 1048\u001b[0m     mi \u001b[38;5;241m=\u001b[39m \u001b[43mmutual_information\u001b[49m\u001b[43m(\u001b[49m\u001b[43mytrue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1049\u001b[0m     sm \u001b[38;5;241m=\u001b[39m smooothing_loss(y)\n\u001b[1;32m   1050\u001b[0m     \u001b[38;5;66;03m#print(\"CC Loss\", cc, \"Gradient Loss\", sm)\u001b[39;00m\n\u001b[1;32m   1051\u001b[0m     \u001b[38;5;66;03m#loss = -1.0 * cc + lamda * sm\u001b[39;00m\n",
      "File \u001b[0;32m~/Dokumenty/MICCAI/voxelmorph2d.py:1030\u001b[0m, in \u001b[0;36mmutual_information\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m   1027\u001b[0m \u001b[38;5;66;03m# .cuda()\u001b[39;00m\n\u001b[1;32m   1028\u001b[0m vbc \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mreshape(vol_bin_centers, o)\n\u001b[0;32m-> 1030\u001b[0m I_a \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexp\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mpreterm\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msquare\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mvbc\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1031\u001b[0m I_a \u001b[38;5;241m=\u001b[39m I_a \u001b[38;5;241m/\u001b[39m torch\u001b[38;5;241m.\u001b[39msum(I_a, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, keepdim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   1033\u001b[0m I_b \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mexp(\u001b[38;5;241m-\u001b[39m preterm \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39msquare(y_pred \u001b[38;5;241m-\u001b[39m vbc))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import voxelmorph2d as vm2d\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils import data\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage.io as io\n",
    "import os\n",
    "from skimage.transform import resize\n",
    "import multiprocessing as mp\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib.lines import Line2D\n",
    "use_gpu = torch.cuda.is_available()\n",
    "\n",
    "from sklearn import metrics, preprocessing, tree\n",
    "from sklearn.metrics import f1_score, make_scorer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sys\n",
    "\n",
    "def timeit(method):\n",
    "    def timed(*args, **kw):\n",
    "        ts = time.time()\n",
    "        result = method(*args, **kw)\n",
    "        te = time.time()\n",
    "        if 'log_time' in kw:\n",
    "            name = kw.get('log_name', method.__name__.upper())\n",
    "            kw['log_time'][name] = int((te - ts) * 1000)\n",
    "        else:\n",
    "            print('%r  %2.2f ms' % \\\n",
    "                  (method.__name__, (te - ts) * 1000))\n",
    "        return result\n",
    "    return timed\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class VoxelMorph():\n",
    "    \"\"\"\n",
    "    VoxelMorph Class is a higher level interface for both 2D and 3D\n",
    "    Voxelmorph classes. It makes training easier and is scalable.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, input_dims, use_gpu=False):\n",
    "        updated_lr = 0.001\n",
    "        self.dims = input_dims\n",
    "        self.vm = vm2d\n",
    "        self.voxelmorph = vm2d.VoxelMorph2d(input_dims[0] * 2, use_gpu)\n",
    "        self.optimizer = optim.Adam(self.voxelmorph.parameters(), lr=updated_lr, weight_decay=0, amsgrad=True)\n",
    "        self.criterion = nn.MSELoss()\n",
    "        #self.optimizer = optim.SGD(\n",
    "        #    self.voxelmorph.parameters(), lr=1e-4, momentum=0.99)\n",
    "        self.params = {'batch_size': 3,\n",
    "                       'shuffle': True,\n",
    "                       'num_workers': 6,\n",
    "                       'worker_init_fn': np.random.seed(42)\n",
    "                       }\n",
    "        self.device = torch.device(\"cuda:0\" if use_gpu else \"cpu\")\n",
    "\n",
    "    def check_dims(self, x):\n",
    "        try:\n",
    "            if x.shape[1:] == self.dims:\n",
    "                return\n",
    "            else:\n",
    "                raise TypeError\n",
    "        except TypeError as e:\n",
    "            print(\"Invalid Dimension Error. The supposed dimension is \",\n",
    "                  self.dims, \"But the dimension of the input is \", x.shape[1:])\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.check_dims(x)\n",
    "        return voxelmorph(x)\n",
    "\n",
    "#     def calculate_loss(self, y, ytrue, n=7, lamda=10, is_training=True):\n",
    "#         loss = self.criterion(y,ytrue) + self.vm.vox_morph_loss(y, ytrue, n, lamda)\n",
    "#         #loss = self.vm.vox_morph_loss(y, ytrue, n, lamda)\n",
    "#         return loss, self.vm.vox_morph_loss(y, ytrue, n, lamda)\n",
    "    \n",
    "    def calculate_loss(self, y, ytrue, alpha, beta, n=9, lamda=0.01, is_training=True):\n",
    "        loss = alpha * self.criterion(y,ytrue) + beta * self.vm.vox_morph_loss(y, ytrue, n, lamda)\n",
    "        return loss, self.vm.vox_morph_loss(y, ytrue, n, lamda)\n",
    "\n",
    "    def train_model(self, batch_moving, batch_fixed, lr = 0.001, n=7, lamda=10, return_metric_score=True):\n",
    "        updated_lr = round(lr * np.power(1 - (0) / 5,0.9),8)\n",
    "        self.optimizer.zero_grad()\n",
    "        batch_fixed, batch_moving = batch_fixed.to(\n",
    "            self.device), batch_moving.to(self.device)\n",
    "        registered_image = self.voxelmorph(batch_moving, batch_fixed)\n",
    "        train_loss, cc_sm_loss = self.calculate_loss(\n",
    "            registered_image, batch_fixed, n, lamda)\n",
    "        train_loss.backward()\n",
    "        self.optimizer.step()\n",
    "        if return_metric_score:\n",
    "            train_dice_score = self.vm.dice_score(\n",
    "                registered_image, batch_fixed)\n",
    "            return train_loss, train_dice_score, updated_lr, cc_sm_loss\n",
    "        return train_loss, updated_lr\n",
    "\n",
    "    def get_test_loss(self, batch_moving, batch_fixed, n=7, lamda=10):\n",
    "        with torch.set_grad_enabled(False):\n",
    "            registered_image = self.voxelmorph(batch_moving, batch_fixed)\n",
    "            val_loss = self.vm.vox_morph_loss(\n",
    "                registered_image, batch_fixed, n, lamda)\n",
    "            val_dice_score = self.vm.dice_score(registered_image, batch_fixed)\n",
    "            return val_loss, val_dice_score\n",
    "\n",
    "\n",
    "class Dataset(data.Dataset):\n",
    "    \"\"\"\n",
    "    Dataset class for converting the data into batches.\n",
    "    The data.Dataset class is a pyTorch class which help\n",
    "    in speeding up  this process with effective parallelization\n",
    "    \"\"\"\n",
    "    'Characterizes a dataset for PyTorch'\n",
    "\n",
    "    def __init__(self, list_IDs):\n",
    "        'Initialization'\n",
    "        self.list_IDs = list_IDs\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the total number of samples'\n",
    "        return len(self.list_IDs)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generates one sample of data'\n",
    "        # Select sample\n",
    "        ID = self.list_IDs[index]\n",
    "\n",
    "        # Load data and get label\n",
    "        fixed_image = torch.Tensor(\n",
    "            resize(io.imread('NIH/test_xrays/' + 'a_' + ID), (224, 224, 3)))\n",
    "        moving_image = torch.Tensor(\n",
    "            resize(io.imread('NIH/test_xrays/' + 'b_' + ID), (224, 224, 3)))\n",
    "        return fixed_image, moving_image\n",
    "\n",
    "    \n",
    "ns = [3, 7, 10, 12]\n",
    "lamdas = [0.4, 3, 5, 10]\n",
    "batch_sizes = [3, 4, 6]\n",
    "num_workers = [2, 4, 6]\n",
    "#max_epochs = [30, 50, 70]\n",
    "max_epochs = [1, 2, 3]\n",
    "\n",
    "def main():\n",
    "    vm = VoxelMorph(\n",
    "        (3, 224, 224))  # Object of the higher level class\n",
    "    DATA_PATH = 'NIH/xrays/'\n",
    "    params = {'batch_size': 3,\n",
    "              'shuffle': True,\n",
    "              'num_workers': 6,\n",
    "              'worker_init_fn': np.random.seed(42)\n",
    "              }\n",
    "    \n",
    "    scorer = make_scorer(f1_score)\n",
    "    \n",
    "    \n",
    "#     DATA_PATH = 'NIH/xrays/'\n",
    "#     params = {'batch_size':[3, 4, 6],\n",
    "#               'shuffle': True,\n",
    "#               'num_workers':[2, 4, 6],\n",
    "#               'worker_init_fn': np.random.seed(42)\n",
    "#               }\n",
    "    \n",
    "    \n",
    "    # max_epochs = 5\n",
    "    filename = list(set([x.split('_')[1] + '_' + x.split('_')[2]\n",
    "                         for x in os.listdir('NIH/test_xrays/')]))\n",
    "    partition = {}\n",
    "    partition['train'], partition['validation'] = train_test_split(\n",
    "        filename, test_size=0.33, random_state=42)\n",
    "    \n",
    "    # Generators\n",
    "    @timeit\n",
    "    def generate_clf_from_search(grid_or_random, clf, params, scorer, X, y):\n",
    "        if grid_or_random == \"Random\":\n",
    "            search_obj = RandomizedSearchCV(clf, params, scoring=scorer)\n",
    "        fit_obj = search_obj.fit(traing_set, training_generator)\n",
    "        best_clf = fit_obj.best_estimator_\n",
    "        return best_clf, search_obj, fit_obj\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    training_set = Dataset(partition['train'])\n",
    "    training_generator = data.DataLoader(training_set, **params)\n",
    "\n",
    "    validation_set = Dataset(partition['validation'])\n",
    "    validation_generator = data.DataLoader(validation_set, **params)\n",
    "    \n",
    "    updated_lr = 0.001\n",
    "    \n",
    "    \n",
    "    \n",
    "    best_hparams = None\n",
    "    best_loss = sys.maxsize\n",
    "    # Loop over epochs\n",
    "\n",
    "    \n",
    "    for n in ns:\n",
    "        for lamda in lamdas:\n",
    "            for batch_size in batch_sizes:\n",
    "                for num_worker in num_workers:\n",
    "                    for epoch in max_epochs:\n",
    "                        start_time = time.time()\n",
    "                        train_loss = 0\n",
    "                        train_dice_score = 0\n",
    "                        val_loss = 0\n",
    "                        val_dice_score = 0\n",
    "                        cc_sm_loss = 0\n",
    "                        for batch_fixed, batch_moving in training_generator:\n",
    "                            loss, dice, updated_lr, cc_sm = vm.train_model(batch_moving, batch_fixed, updated_lr)\n",
    "                            train_dice_score += dice.data\n",
    "                            train_loss += loss.data\n",
    "                            cc_sm_loss += cc_sm\n",
    "                        print('[', \"{0:.2f}\".format((time.time() - start_time) / 60), 'mins]', 'After', epoch + 1, 'epochs with', n, 'n', lamda, 'lamda', batch_size, 'batch_size', num_workers, 'num_workers', 'Average training loss is ', train_loss *\n",
    "                              params['batch_size'] / len(training_set), 'and average DICE score is', train_dice_score.data * params['batch_size'] / len(training_set), \n",
    "                              'and average cc loss is', cc_sm_loss * params['batch_size'] / len(training_set))\n",
    "                        # Testing time\n",
    "                        start_time = time.time()\n",
    "                        for batch_fixed, batch_moving in validation_generator:\n",
    "                            # Transfer to GPU\n",
    "                            loss, dice = vm.get_test_loss(batch_moving, batch_fixed)\n",
    "                            val_dice_score += dice.data\n",
    "                            val_loss += loss.data\n",
    "                            \n",
    "                            \n",
    "                        if best_hparams is None or val_loss < best_loss:\n",
    "                            best_hparams = (n, lamda, batch_size, num_worker, max_epochs)\n",
    "                            best_loss = val_loss    \n",
    "                            \n",
    "                            \n",
    "                            \n",
    "                        print('[', \"{0:.2f}\".format((time.time() - start_time) / 60), 'mins]', 'After', epoch + 1, 'epochs, the Average validations loss is ', val_loss *\n",
    "                              params['batch_size'] / len(validation_set), 'and average DICE score is', val_dice_score.data * params['batch_size'] / len(validation_set))\n",
    "                        print(f\"best hparams: {best_hparams}\")\n",
    "                        \n",
    "    \n",
    "    \n",
    "    \n",
    "    best_clf_grid, search,fit = generate_clf_from_search(\"Random\", \n",
    "                                         clf, \n",
    "                                         params, \n",
    "                                         scorer, \n",
    "                                         training_set, \n",
    "                                         training_generator)\n",
    "\n",
    "    fit.cv_results_['params'][0]\n",
    "    fit.cv_results_['mean_test_score'][0]\n",
    "    len(fit.cv_results_['mean_test_score'])\n",
    "\n",
    "                        \n",
    "                        \n",
    "                        \n",
    "                        \n",
    "                        \n",
    "                        \n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce169d0f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
